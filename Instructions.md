# üìö Instructions to run: Advanced House Prices Prediction Project

Welcome to the Advanced House Prices Prediction project! This comprehensive guide will walk you through every step of building a complete machine learning solution from data preprocessing to deployment to showcasing your work and building your online presence, **needed to get hired in the industry**.

## üéØ Learning Objectives [?????]

By completing this project, you will learn:

- üßπ **Data Cleaning & Feature Engineering:** Transform raw data into model-ready features
- ü§ñ **Machine Learning:** Build and train regression models for price prediction
- üöÄ **Deployment:** Create an interactive web application using Streamlit
- üìä **Model Evaluation:** Understand and interpret performance metrics


## üöÄ Quick Start [?????]

Before diving into the full project, we recommend starting with our simplified Party-Time jupyter notebook in Google Colab. This **condensed version** introduces the **main concepts** and workflow without the complexity of the complete implementation. 
Once you're comfortable with the fundamentals, **return here for the comprehensive walkthrough**.

**üìì [Access Party-Time Notebook](https://colab.research.google.com/drive/18g9kSY_tkqn6PIERJm32mDFFHu3KnJDU?usp=sharing)** - *A beginner-friendly introduction to get you started*




## üöÄ Getting Started

Follow this comprehensive step-by-step workflow to complete the project. Each step includes both execution instructions and understanding of what you're accomplishing.

### Step 1: Environment Setup

Choose one of the following setup methods and follow the detailed instructions in [Setup Environment Guide](./Docs/Setup_Environment.md):[?????]

**Quick Setup:**

**Step 1: Fork the Repository**
1. Sign in to your GitHub account
2. Navigate to https://github.com/compu-flair/Kaggle_Advanced_House_Prices
3. Click the `Fork` button in the top-right corner
4. Click `Create fork` to make a copy of the project in your GitHub account

**Step 2: Clone Your Fork**
1. On your forked repository page, click the green `Code` button
2. Select the `SSH` tab (if you see "You don't have any public SSH keys," follow the [SSH Setup Guide](./Docs/Add_SSH_to_GitHub.md))
3. Copy the provided SSH URL 


```bash
# Clone the repository
git clone <url-to-your-forked-repo-from-steps-above>
cd Kaggle_Advanced_House_Prices

# Create the environment
conda env create -f environment.yml

# Activate the environment
conda activate kaggle-house-prices

# (Optional) Update the environment if you change dependencies
conda env update -f environment.yml --prune

# Add conda kernel to jupyter notebook
conda install ipykernel
python -m ipykernel install --user --name kaggle-house-prices --display-name "kaggle-house-prices"
```

**Additional Setup Steps:**
* **VSCode Python Interpreter Setup:**
   - **Windows/Linux:** Press `Ctrl+Shift+P` 
   - **Mac:** Press `Cmd+Shift+P` 
- Select "Python: Select Interpreter", then choose the "kaggle-house-prices" interpreter.
* Once you open the Jupyter Notebook, it should automatically use the "kaggle-house-prices" kernel. If not, please restart VSCode. And if not successful, then on the top right corner of the notebook, you can manually select the kernel by clicking on it and choosing "kaggle-house-prices". You most likely will find it in the Jupyter kernel list.


### Step 2: Kaggle Setup

Before you can download the dataset, you need to set up Kaggle credentials. Follow the complete guide in [Setup Kaggle](./Docs/Setup_Kaggle.md)[?????] which includes:

1. Creating your Kaggle account
2. Joining the competition and accepting rules
3. Setting up API credentials
4. Downloading the dataset


### Step 3: Initial Setup and Data Acquisition

**üéØ Project Status:** Getting Started (Phase 1 of 4)

1. **Download the Dataset**
   - Join the [Kaggle competition](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)
   - Accept the competition rules
   - Download dataset:
     ```bash
     kaggle competitions download -c house-prices-advanced-regression-techniques -p data/
     ```
   
   **üí° What you're doing:** Accessing the Ames Housing dataset, one of the most popular datasets for regression problems. This dataset contains 79 explanatory variables describing residential homes in Ames, Iowa.

### Step 4: Data Exploration, Cleaning, and Model Building

1. **Open the Jupyter Notebook:**
In the left panel of the VSCode, click on the explorer tab, navigate to the notebook file, click and open it. 


2. **Go through the notebook, read, understand, and run cells one by one.**[?????]


### Step 5: Turn Your ML Model Into a Web Application

**üí° What you're doing:** Now that you have a trained machine learning model, you'll learn how to use it as an interactive web application using Streamlit. This step transforms your data science work into a user-friendly interface where anyone can input house characteristics and get price predictions in real-time using your trained model.

1. **Understand the Application Architecture**
   
   **üìÅ Key Files Explained:**
   
   - **`main.py`**: Streamlit application entry point
     - Orchestrates the entire web application
     - Handles navigation between different views
   
   - **`views/house_price.py`**: Main prediction interface
     - Loads the trained model
     - Creates input forms for house features
     - Makes predictions and displays results
   
   - **`models/schemas.py`**: Data validation schemas (Pydantic)
     - Ensures input data has correct format
     - Validates feature types and ranges
     - Provides clear error messages for invalid inputs
   
   - **`configs/config.py`**: Application configuration
     - Model file paths and settings
     - Default values for features
     - App parameters and constants

2. **Launch the Streamlit Application**
   ```bash
   streamlit run main.py
   ```
   - Open your browser to `http://localhost:8501`

   **üéÆ Explore These Features:**
   Use the **left panel** to select the following features
   - **House Price Prediction**: 
      - This page will use the model trained during data_cleaning_and_feature_engineering.ipynb to predict prices
   - **Custom Linear Regression**:
      - Upload a csv file of any dataset, for example `data/train.csv`
      - Data will be processed and a linear regression will be trained
      - Go down the page, select your target column (the y) from drop-down labeled `Select label (Y) column`
      - select as many columns as you wish to serve as your X in the linear regression in `Select feature columns (X)` dropdown
      - Click the `Start Training` button. This will train the linear regression.
      - Under `Make a Prediction`, choose some values for each of the features, and then click `Predict` to get a prediction.
   - **Custom XGBoost**:
      - Same as in `Custom Linear Regression` above with the difference that an XGBoost model will be used instead of linear regression. 
   - **About**: 
      - Here you need to explain what the application is doing and how to use it. (After you make your own changes.)

   **‚úÖ Checkpoint:** After this step, you should have:
   - A working web application
   - Ability to make predictions through the UI
   - Understanding of one simple way of how an ML model can be turned into a web application. (There are more advanced methods that go beyond the scope of this project.)

### üöÄ One-Click Deployment & Showcase

**üí° Ready to share your work with the world?** Your Streamlit application includes a built-in deployment feature that makes it easy to showcase your project online:

1. **Deploy to Streamlit Cloud:**
   - In your running application, look for the `Deploy` button in the top-right corner and click it.
   - Choose the `Streamlit Community Cloud` and click the `Deploy now`
   - Sign in with your GitHub account when prompted
   - Select your repository and branch
      - Use the green `Code` button and copy the HTML url
   - Click the `Deploy` button
   - Your app will be automatically deployed and accessible via a public URL
   - Save the public URL to be used when showcasing your work.

2. **Share Your Live Demo:**
   - Copy the deployment URL and add it to your GitHub repository README
   - Share the link on LinkedIn, Twitter, or your portfolio
   - Include it in job applications as a live demonstration of your skills

3. **Benefits of Live Deployment:**
   - **Professional Portfolio**: Demonstrate real, working applications to potential employers
   - **Easy Sharing**: Anyone can test your model without installing anything
   - **Automatic Updates**: Your deployment updates automatically when you push changes to GitHub



## üê≥ Alternative: Docker Deployment (Production-Ready)

If you prefer containerized deployment:

1. **Using Docker Commands**
   ```bash
   docker build -t house-prices-app .
   docker run --rm -p 8501:8501 house-prices-app
   ```

2. **Using the Provided Script**
   ```bash
   bash start.sh
   ```

**üí° When to use Docker:** Choose this option if you want to deploy the application in a production environment or if you're having dependency conflicts.


## üéâ Showcase Your Work

Follow the [GitHub Showcase Guide](./Docs/Show_Case_Github.md) to:
- Create an impressive GitHub repository
- Write a professional README
- Add screenshots and demos
- Share your project with the community

## üîÑ Next Steps

After completing this project, consider these extensions:

1. **Advanced Feature Engineering**: Try creating polynomial features, interaction terms, or domain-specific features
2. **Ensemble Methods**: Combine multiple models for better predictions
3. **Deep Learning**: Experiment with neural networks for regression
4. **MLOps**: Learn about model deployment, monitoring, and versioning


## üìà Success Metrics

Track your progress with these goals:

### Basic Level ‚úÖ
- [ ] Successfully set up development environment
- [ ] Complete data cleaning notebook
- [ ] Train a basic Linear Regression model
- [ ] Run the Streamlit application locally
- [ ] Make predictions using the web interface

### Intermediate Level üöÄ
- [ ] Understand and explain the feature engineering process
- [ ] Implement model evaluation and comparison
- [ ] Modify the Streamlit app (add new features or improve UI)
- [ ] Experiment with different model parameters

### Advanced Level üéØ
- [ ] Implement additional machine learning algorithms
- [ ] Create new features and test their impact
- [ ] Optimize model performance through hyperparameter tuning
- [ ] Deploy the application (using Docker or cloud platforms)
- [ ] Create comprehensive documentation and showcase the project






## **Good luck with your machine learning journey! üöÄ**

Remember: The goal is not just to complete the project, but to understand the underlying concepts and develop practical skills you can apply to future challenges.
